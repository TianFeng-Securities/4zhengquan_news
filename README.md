# 4zhengquan_news

需要注意的是部分日期的内容只有四大证券报其中的三家，其他的一家并不是四大证券报，比如21世纪世纪经济报，这种情况下是只留下真正的三家名副其实的四大证券报，而不采用21世纪经济报

四大证券报新闻数据抓取、清理、格式化

是一个将新浪网上的四大证券报专题的数据爬取下来的爬虫：

![总览页](/img/总览页.png)

发送请求和返回数据的思路比较简单。

比较难的是后续的数据清洗和格式化走了比较多的弯路。算法不难，但是需要多思考。

![内容页](/img/内容页.png)


运行之后的输出结果：

![运行结果页](/img/运行结果.png)

运行过程如下图所示：

![运行过程](/img/运行过程.gif)

由于报纸的编辑在更新的时候，不同的编辑风格可能不一样。如[2018年12月9号](https://finance.sina.com.cn/stock/y/2019-12-09/doc-iihnzhfz4538431.shtml)
的情况是缺少了证券时报的内容，却多出来的了第一财经日报的内容，而第一财经日报的内容不需要。所以会少。

![20191209误差](/img/1209.png)


为解决此问题，以及确保无误，设计了误差分析模块，原始的数据跑完之后会在**原始数据**文件夹里面，需要将**四大证券报原始数据.xlsx**
中的数据拷入**误差分析**的文件夹里面的**四大证券报误差分析.xlsx**的**原始数据**sheet，然后在**误差分析结果**的sheet里面会计算如下的结果：

![误差分析结果](/img/误差分析结果.png)

注意最后一列是自己根据回溯[网站](http://finance.sina.com.cn/focus/zqbjh/)原始信息，添加的备注。


## 到此完结啦~~~
